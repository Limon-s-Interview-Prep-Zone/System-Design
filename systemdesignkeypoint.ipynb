{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [System Design Interviews](https://blog.algomaster.io/p/how-to-answer-a-system-design-interview-problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to approach System design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Understand the Problem and Scope**\n",
    "   - What are we building? Define the purpose and main objectives.\n",
    "   - What are we not building? Clarify boundaries to avoid scope creep.\n",
    "   - Who are the users? Identify target users and their needs.\n",
    "   - Why are we building it? Understand business goals and motivations.\n",
    "2. **Requirements**:\n",
    "   - Functional\n",
    "     * What features will the systems have? Define `core features`, `workflows`, and `user interactions`\n",
    "   - Non Functional(Difficult)\n",
    "     * Performance\n",
    "       * Latency\n",
    "       * Replication\n",
    "       * Availability\n",
    "     * Scalability\n",
    "       * Throughput\n",
    "       * Storage\n",
    "     * Reliability\n",
    "       * Fault tolerance\n",
    "       * Disaster Recovery Strategies\n",
    "     * Security\n",
    "       * Authentication and authorization\n",
    "       * Data encryption and privacy\n",
    "     * Budget\n",
    "       * Budget constraints and trade-offs\n",
    "3. **Capacity Estimation**\n",
    "   - Traffic estimation\n",
    "   - Storage Estimation\n",
    "   - Bandwidth Needs\n",
    "4. **High Level Design:** Focus on high level design.\n",
    "   - `System architecture`: Decide between monolithic, microservices, or serverless.\n",
    "   - `Indentify Components`:`Authentication service, database layer, caching layer, etc`\n",
    "   - `Define data flow`: High level representation of data movement.\n",
    "   - `Redundency and Failover`\n",
    "     - Plan for backup systems and disaster recovery.\n",
    "5. **Data Modeling**\n",
    "   - `Database Schema`: Design relationships between entities for SQL databases.\n",
    "   - `NoSQL Design`: Optimize for key-value, document, or graph-based queries.\n",
    "   - `Indexes and Partitions`: Plan for performance optimization.\n",
    "6. **Low Level Design(Detail Design)**\n",
    "   - ***Component Design:*** \n",
    "     * Break down each component from the high-level architecture into smaller, functional modules.\n",
    "     * Clearly define the responsibilities of each module to ensure cohesion and minimize coupling.\n",
    "     * Login Module, Session management\n",
    "   - `Diagram:`\n",
    "     * Class Diagram, Sequence Diagram, State Diagram\n",
    "   - `API interfaces`\n",
    "     * POST /login: Input: {email, password}. Output: {token}.\n",
    "     * POST /logout: Input: {token}. Output: {success: true}.\n",
    "   - `Data Structure`\n",
    "7. **Right tools and technique**\n",
    "   - `Databases`: SQL (PostgreSQL, MySQL) or NoSQL (MongoDB, Cassandra).\n",
    "   - `Backend Frameworks`: Django, Flask, Spring Boot, ASP.NET, etc.\n",
    "   - `Frontend Frameworks`: React, Angular, Vue.js, etc.\n",
    "   - `Caching`: Redis, Memcached. Message Queues: RabbitMQ, Kafka, or AWS SQS.\n",
    "   - `Search Engines`: Elasticsearch or Solr.\n",
    "   - `Load Balancers`: Nginx, HAProxy, or AWS Elastic Load Balancer (ELB).\n",
    "8. **Design Api**\n",
    "   - Define Endpoints: RESTful or GraphQL APIs.\n",
    "   - Specify Details: HTTP methods, payloads, and headers.\n",
    "   - Error Handling: Consistent error codes and messages.\n",
    "   - Versioning: Plan for API versioning to handle future changes.\n",
    "   - Rate Limiting: Prevent abuse and ensure fair usage.\n",
    "   - Documentation: Create comprehensive API documentation for developers.\n",
    "9.  **Deployment and Monitoring**\n",
    "    - `Deployment strategies`: Blue-Green, Canary, or Rolling updates.\n",
    "    - `Monitoring`:\n",
    "      * Metrics: Prometheus, Grafana, DataDog\n",
    "      * Log: ELK stack.\n",
    "    - Alerting: PagerDuty for incident response.\n",
    "10. **Testing and validation**\n",
    "    - Unit Tests: Validate individual functions or modules.\n",
    "    - Integration Tests: Ensure components work together.\n",
    "    - Performance Testing: Load and stress testing (e.g., JMeter).\n",
    "    - End-to-End Tests: Validate workflows and user journeys.\n",
    "    - Security Testing: Penetration testing, vulnerability scanning.\n",
    "11. **Security Considerations**\n",
    "    - Data encryption (at rest and in transit).\n",
    "    - Secure API endpoints (OAuth2, OpenID Connect).\n",
    "    - DDoS protection.\n",
    "    - Regular vulnerability scanning and patching.\n",
    "12. **Iterate and Review**\n",
    "    - Feedback loop\n",
    "    - Update and Patches:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scoping: What should the system do and what is out of scope?\n",
    "Scoping helps to define the boundaries of the system.\n",
    "- What we are building?\n",
    "- What we are not building?\n",
    "\n",
    "#### Example: Design a food Delivery System(like Uber Eats)\n",
    "1. In Scope(What systems will do):\n",
    "   - Allow users to view menus and order food from resturants\n",
    "   - Allow resturants to receive order\n",
    "   - Enable delivery driver to pick up and deliver orders.\n",
    "2. Out of scope(What the system won't do):\n",
    "   - Providing in-app customer review\n",
    "   - Handling Grocery deliveries(only food item this time) \n",
    "### Functional Requirement: What features will the systems have?\n",
    "Functional requirements are the specific features the systems needs.` Functional requirements describe what the system will actually do—what features developers need to build.`\n",
    "   - What the systems will do?\n",
    "   - How user will interact with it?\n",
    "#### Food delivery app:\n",
    "1. User Side:\n",
    "   - Users can search for nearby restaurants.\n",
    "   - Users can place food orders and make payments.\n",
    "   - Users can track delivery status in real time.\n",
    "2. Restaurant Side:\n",
    "   - Restaurants can receive and confirm orders.\n",
    "   - Restaurants can update menu items and prices.\n",
    "3. Delivery Driver Side:\n",
    "   - Drivers can view and accept delivery requests.\n",
    "   - Drivers can update delivery status (e.g., \"Picked Up,\" \"Delivered\").\n",
    "4. Admin Side:\n",
    "   - Admins can monitor orders, payments, and users.\n",
    "5. APIs:\n",
    "   - POST /order: Place a new order.\n",
    "   - GET /restaurants: Retrieve a list of nearby restaurants.\n",
    "\n",
    "### Non Functional Requirement:\n",
    "Non-functional requirements ensure the system works well under real-world conditions (high traffic, failures, etc.).\n",
    "1. `Performance:` How fast or efficient? `Search latency<200ms`\n",
    "   - `Latency:` Query to our database is fast as possible.\n",
    "     - Read fast or write slow.\n",
    "2. `Scalability:` Can it handle growing users or traffic? `10k orders/minute`\n",
    "   1. Latency: Time taken to process a request.\n",
    "   2. Throughput: Number of requests handled per second.\n",
    "   3. CPU/Memory Utilization: Server resource usage.\n",
    "   4. Error Rates: Number of failed requests.\n",
    "   5. Storage Capacity\n",
    "3. `Availability:` How reliable is the system?`99.99% uptime`\n",
    "   1. availability=#succesfull reponse/#request\n",
    "4. `Security:` How secure is the data?`use https and encryption`\n",
    "\n",
    "### Back of the envelope calculation:\n",
    "- Active user =100m user\n",
    "- each person Read = 100 tweet/perday\n",
    "- Write each person .1 tweet so total tweet=10m \n",
    "- read total=100*100m=10b\n",
    "-  Read Throughput=10b/100k = 100,000\n",
    "-  Read Throughput=10m/100k = 100\n",
    "### Storage\n",
    "\n",
    "#### mixed\n",
    "1. Requirements clarifications\n",
    "   1. Functional requirement\n",
    "   2. Non-Functional requirement\n",
    "   3. Extended Requirement\n",
    "2. Estimation and Constraints\n",
    "3. Data model design\n",
    "4. API design\n",
    "5. High level component design\n",
    "6. Detailed design\n",
    "7.  Indetify and resolve bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate limiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency & Throughput & Response Time\n",
    "In the scenario where a user submits a form, and the backend server processes it by sending the payload to a database, latency and response time can be broken down into the steps involved.\n",
    "1. **Throughput**: Throughput is the amount of data processed by a system in a given amount of time. It is typically measured in units such as `transactions per second (TPS)`, `requests per second (RPS)`, or `bytes per second (BPS)`.\n",
    "   - The **backend** handles `100 requests per second`, and the **database** can handle `200 queries per second`.\n",
    "   - Throughput is limited by **backend** processing.\n",
    "   - `Throughput depends on system capacity and scalability`.\n",
    "\n",
    "\n",
    "2. **`Latency`**: Latency is the time it takes for a data packet to travel from the source to the destination. It is typically measured in `milliseconds (ms)` or `microseconds (µs)`.\n",
    "   - ***`User → Backend Server`***: Time for the form submission data to reach the backend server. Ex: `latency=50ms`\n",
    "   - ***`Backend Server → Database`***: Time for the backend server's payload to reach the database server. Ex: `latency=30ms`\n",
    "\n",
    "3. **`Response time`**: Response time is the total time taken to complete a database transaction, `from the initial request to the final response`. It encompasses `latency`, `processing time`, and any `additional delays`.\n",
    "   - ***`Backend Server Processing`***: Time spent processing the payload (e.g., validation, formatting).`Backend processing time: 100 ms.`\n",
    "   - ***`Database Processing`***: Time spent executing the query (e.g., inserting data).`Database processing time: 200 ms.`\n",
    "   - ***`Combined Network Delays`***: Includes the time taken for the data to travel back and forth between the `user, backend server, and database`. $50+30=80ms$\n",
    "   - **`[Total]`=**$100+200+80=380ms$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we scale in the above scenario?\n",
    "#### 1#Improve Latency from Client to backend server:\n",
    "1. `Use Content Delivery Network (CDN)`: Place the server closer to the user geographically to reduce network transmission time.\n",
    "2. `Minimize Payload Size`: Compress the data sent from the user’s browser to the backend (e.g., use gzip).\n",
    "Send only essential fields in the form.\n",
    "3. `Enable HTTP/2 or HTTP/3`: These protocols are faster than HTTP/1.1 and reduce latency by using multiplexing and better connection management.\n",
    "4. `Optimize SSL/TLS Handshake`: Use session resumption or faster key exchange algorithms like TLS 1.3.\n",
    "5. `Persistent Connections`: Use keep-alive connections to reduce the overhead of opening new connections for every request.\n",
    "\n",
    "#### 2#Optimize Backend Processing\n",
    "1. Efficient Request Validation: Use lightweight validation libraries and ensure logic is efficient.\n",
    "2. Reduce Backend Logic Overhead:\n",
    "   - Use efficient algorithms for processing.\n",
    "   - Precompute or cache repetitive operations.\n",
    "3. Asynchronous Processing:\n",
    "   - Offload heavy processing tasks (e.g., email notifications) to a background job queue (e.g., RabbitMQ, Kafka).\n",
    "4. Connection Pooling:\n",
    "   - Maintain a pool of database connections to avoid the overhead of opening and closing connections for each request.\n",
    "5. Optimize APIs:\n",
    "   - Reduce the size and complexity of APIs, e.g., use RESTful best practices or GraphQL to fetch only necessary data.\n",
    "\n",
    "#### 3#Reduce Latency Between Backend Server and Database\n",
    "1. Optimize Database Connections:\n",
    "   - Use a database connection pool to reuse existing connections instead of creating new ones for every request.\n",
    "2. Reduce Query Complexity:\n",
    "   - Simplify SQL queries by avoiding unnecessary joins and subqueries.\n",
    "   - Fetch only the required columns instead of using SELECT *.\n",
    "3. Indexing:\n",
    "   - Ensure proper indexing on frequently queried columns, such as the columns in the form data being saved or queried.\n",
    "4. Caching:\n",
    "   - Use a caching layer like Redis or Memcached to store frequently accessed data and reduce database hits.\n",
    "5. Minimize Network Latency to Database:\n",
    "   - Host the database server close to the backend server.\n",
    "6. Use Stored Procedures:\n",
    "   - Move some processing logic to the database using stored procedures to avoid multiple round trips between backend and database.\n",
    "7. Database Partitioning and Sharding:\n",
    "   - Split large tables into smaller, more manageable chunks to reduce query times.\n",
    "\n",
    "#### 4#Reduce Latency Between Database and Backend\n",
    "1. Efficient Data Transfer:\n",
    "   - Compress the data sent from the database to the backend.\n",
    "   - Use optimized data serialization formats (e.g., Protobuf, Avro).\n",
    "2. Pagination for Large Results:\n",
    "   - Return only a subset of the data using LIMIT and OFFSET.\n",
    "\n",
    "#### 5#Reduce Latency Between Backend and User\n",
    "1. Minimize Response Payload Size:\n",
    "   - Send only necessary data back to the user.\n",
    "   - Use JSON or other lightweight formats.\n",
    "2. Enable Compression:\n",
    "   - Use gzip or Brotli compression for server responses.\n",
    "3. Keep Connections Alive:\n",
    "   - Reuse TCP connections with persistent connections.\n",
    "4. Use Edge Caching:\n",
    "   - Cache common responses (e.g., success messages) at the edge using CDNs.\n",
    "\n",
    "#### 6#General Optimization\n",
    "1. Parallel Processing:\n",
    "   - Execute tasks that don’t depend on each other (e.g., form validation and logging) in parallel.\n",
    "2. Use Load Balancing:\n",
    "   - Distribute requests across multiple backend and database servers to avoid bottlenecks.\n",
    "3. Monitor Performance:\n",
    "   - Use tools like New Relic, Datadog, or AWS CloudWatch to identify latency bottlenecks.\n",
    "4. Optimize Server and Database Resources:\n",
    "   - Ensure sufficient CPU, memory, and disk I/O capacity to handle the workload efficiently.\n",
    "5. Switch to Faster Protocols:\n",
    "   - Use WebSockets or gRPC for faster communication between backend and database or backend and user.\n",
    "\n",
    "\n",
    "---\n",
    "### How to improve throughput?\n",
    "#### 1#Optimize Backend Server Performance\n",
    "1. Use Asynchronous Programming\n",
    "   - Implement asynchronous processing to handle multiple requests concurrently without waiting for blocking operations to finish.\n",
    "   - Example: Use async/await in Node.js or ASP.NET Core for non-blocking I/O operations.\n",
    "2. Increase Concurrency\n",
    "   - Configure the backend server to handle more concurrent connections using:\n",
    "      - Thread pools (e.g., adjust worker threads in .NET).\n",
    "      - Event-driven architectures (e.g., Node.js or Nginx).\n",
    "3. Load Balancing\n",
    "   - Use load balancers (e.g., HAProxy, AWS ELB) to distribute incoming requests across multiple servers, preventing overload on a single instance.\n",
    "4. Connection Pooling\n",
    "   - Use a connection pool to manage database connections efficiently and reduce the overhead of creating new connections for each request.\n",
    "5. Stateless Design\n",
    "   - Design the backend to be stateless so multiple instances can independently handle requests without sharing state.\n",
    "\n",
    "#### 2#Optimize Database Performance\n",
    "1. Query Optimization\n",
    "   - Use efficient queries (e.g., avoid SELECT *, use proper indexes, and limit results).\n",
    "   - Reduce join complexity and optimize schema design.\n",
    "2. Caching\n",
    "   - Cache frequently accessed data in-memory using Redis or Memcached.\n",
    "   - Use query caching to avoid repetitive execution of the same database queries.\n",
    "3. Partitioning\n",
    "   - Horizontal Partitioning (Sharding): Split large tables into smaller shards distributed across multiple servers.\n",
    "   - Vertical Partitioning: Separate rarely accessed columns into different tables.\n",
    "4. Denormalization:\n",
    "   - Duplicate data to reduce the need for joins in read-heavy workloads.\n",
    "5. Materialized Views:\n",
    "   - Precompute and store the results of expensive queries for reuse.\n",
    "6. Read/Write Optimization\n",
    "   - Implement read replicas to handle read-heavy operations separately from writes.\n",
    "   - Use write batching to combine multiple write operations into a single transaction.\n",
    "\n",
    "#### 3#Optimize Network and Payloads\n",
    "1. Reduce Payload Size\n",
    "   - Minimize the data sent between the client, backend, and database.\n",
    "   - Use compressed formats (e.g., gzip) and lightweight protocols like JSON.\n",
    "2. Use Efficient Protocols\n",
    "   - Use HTTP/2 or HTTP/3 for faster request handling and multiplexing.\n",
    "3. Proximity\n",
    "   - Place servers closer to end-users and database servers to reduce network latency.\n",
    "\n",
    "#### 4#Optimize Application Logic\n",
    "1. Batch Processing\n",
    "   - Instead of processing each request independently, batch similar operations and execute them together.\n",
    "   - Example: Process multiple form submissions in one database transaction.\n",
    "2. Pre-computation\n",
    "   - Precompute and cache results of expensive operations to serve requests faster.\n",
    "3. Offload Non-Critical Tasks\n",
    "   - Move tasks like sending notifications or logging to a background queue using tools like RabbitMQ, Kafka, or Celery.\n",
    "\n",
    "#### 5#Scale Infrastructure\n",
    "1. Horizontal Scaling\n",
    "   - Add more instances of the backend and database servers to distribute load.\n",
    "   - Example: Scale using container orchestration tools like Kubernetes or ECS.\n",
    "2. Vertical Scaling\n",
    "   -  Upgrade server hardware to handle more requests (e.g., increase CPU cores, RAM, or disk speed).\n",
    "3. Database Sharding\n",
    "   - Distribute database tables across multiple servers to handle larger volumes of data and queries.\n",
    "4. Auto Scaling: Implement auto-scaling mechanisms to dynamically adjust resources based on traffic.\n",
    "5. High-Performance Storage:\n",
    "   - Use SSDs or faster disks for better I/O performance.\n",
    "6. Database Configuration:\n",
    "   - Adjust database settings like buffer pool size, query cache size, and thread concurrency for better performance.\n",
    "---\n",
    "### Database Scaling:\n",
    "1. Vertical Scaling (Scaling Up): Add more resources (CPU, memory, storage) to a single database server.\n",
    "   - Advantages:\n",
    "     - Simple implementation.\n",
    "     - No changes required to the database architecture or application logic.\n",
    "   - Challenges:\n",
    "     - Limited by hardware constraints.\n",
    "     - Downtime might be required during upgrades.\n",
    "   - Examples: Upgrading to a larger instance type in cloud environments (e.g., AWS RDS).\n",
    "2. Horizontal Scaling (Scaling Out): Distribute the database load across multiple servers.\n",
    "   - Sharding: Split data into smaller, independent partitions (shards). Each shard is hosted on a separate server.\n",
    "     - Example: A user table can be sharded by user ID ranges (e.g., IDs 1–1,000 on Server A, IDs 1,001–2,000 on Server B).\n",
    "   - Replication: Create multiple copies of the database.\n",
    "     - Primary server handles writes, and replicas handle reads.\n",
    "   - Distributed Databases: Use systems like MongoDB, Cassandra, or Amazon Aurora that natively support horizontal scaling.\n",
    "  - Advantages:\n",
    "    - Scales beyond the limitations of a single server.\n",
    "    - High availability and fault tolerance with replication.\n",
    " - Challenges:\n",
    "   - Increases complexity of the database design and application logic.\n",
    "   - Requires proper partitioning strategy to avoid hotspots.\n",
    "  \n",
    "3. Scaling Strategies Based on Workload\n",
    "   - Write-Heavy Workloads:\n",
    "     - Use sharding to distribute writes across multiple servers.\n",
    "     - Optimize schema to reduce contention and conflicts during writes.\n",
    "   - Read-Heavy Workloads:\n",
    "     - Implement read replicas to offload reads from the primary database.\n",
    "     - Use caching to serve frequently read data directly.\n",
    "   - Mixed Workloads: Combine sharding and replication (e.g., shard the data and use replicas for each shard).\n",
    "4. Advanced Scaling Techniques\n",
    "   - Auto-Scaling: Use cloud-based auto-scaling features to dynamically adjust resources based on demand.\n",
    "   - Multi-Region Deployments: Distribute the database across multiple regions for global applications to reduce latency.\n",
    "   - Database as a Service (DBaaS): Use managed services like AWS Aurora, Google Cloud Spanner, or Azure SQL Database that support seamless scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalability:\n",
    "Scalability means having strategies for keeping performance good, even when load increases(ex- more user, adding new features).\n",
    "1. Vertical Scalability:\n",
    "   - Adding more resources (CPU, RAM, etc.) to a single server.\n",
    "   - When you need a quick, simple solution but have a single-node bottleneck.\n",
    "   - Example: Upgrading a database server to handle more queries.\n",
    "2. Horizontal Scalability:\n",
    "    - Adding more servers or nodes to distribute the load.\n",
    "    - When workloads grow significantly, and you need resilience and scalability.\n",
    "   - Example: Using a load balancer to distribute traffic across multiple web servers.\n",
    "\n",
    "## How can we make a system scalable?\n",
    "1. Database Sharding: Distribute data across multiple nodes.\n",
    "2. Load Balancing: Distribute user requests across multiple servers.\n",
    "3. Caching: Store frequently accessed data in-memory (e.g., Redis, Memcached)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching:\n",
    "A cache's primary purpose is to increase data retrieval performance by reducing the need to access the underlying slower storage layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of cache:***\n",
    "\n",
    "1. $L1$:\n",
    "   - Closest to CPU core or inside the cpu\n",
    "   - Small in size, usally ranging from `16kb to 128kb`.\n",
    "   - Stores the most frequently accessed data and instructions for immediate use by the CPU.\n",
    "2. L2:\n",
    "   - Inside the CPU\n",
    "   -  Larger than L1, typically ranging from 256 KB to 1 MB per core.\n",
    "3. L3:\n",
    "   - Inside the CPU.\n",
    "   - typically ranging from 2 MB to 50 MB or more.\n",
    "4. L4:\n",
    "   - Outside of the CPU.\n",
    "   - Larger in size.\n",
    "\n",
    "5. Memory Cache: \n",
    "   - involve system RAM or other software-based caching solutions, not the CPU caches.\n",
    "   - `File System Cache:` Part of the operating system that caches frequently accessed files in RAM.\n",
    "   - `Database Cache:` Stores frequently accessed data in RAM to speed up database queries.\n",
    "   - `Application-Level Cache:` Such as Redis or Memcached, which stores frequently used data in RAM to improve application performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache hit and Cache miss\n",
    "1. Cache Hit:\n",
    "    - the data is found and read, it's considered a cache hit.\n",
    "    - hot cache is a instance when data retreeved from `L1`.\n",
    "    - Cool cache is a instance when data retrieved from `L3 or lower`.\n",
    "2. Cache Miss: A cache miss refers to the instance when the memory is searched, and the data isn't found. When this happens, the content is transferred and written into the cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data into cache:\n",
    "1. Cache aside: Data is written into the cache and the corresponding database simultaneously.\n",
    "2. Write through: The application uses the cache as the main data store, reading and writing data to it, while the cache is responsible for reading and writing to the database:\n",
    "3. Write behind: Where the write is only done to the caching layer and the write is confirmed as soon as the write to the cache completes. The cache then asynchronously syncs this write to the database.\n",
    "\n",
    "`pros:`<br>\n",
    "1. reduce latency and high throughput for write-intensive applications.\n",
    "\n",
    "`cons:`<br>\n",
    "1. a risk of data loss in case the caching layer crashes.\n",
    "### Refresh a head:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distrributed cache:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global cache:\n",
    "When the requested data is not found in the global cache, it's the responsibility of the cache to find out the missing piece of data from the underlying data store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDN:\n",
    "A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon's CloudFront support dynamic content. The site's DNS resolution will tell clients which server to contact.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1. Users receive content from data centers close to them\n",
    "2. Your servers do not have to serve requests that the CDN fulfills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CDN Types:\n",
    "\n",
    "1. Push CDNs: Push CDNs receive new content whenever changes occur on the server. We take full responsibility for providing content, uploading directly to the CDN, and rewriting URLs to point to the CDN. We can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage. <br>Sites with a small amount of traffic or sites with content that isn't often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.\n",
    "\n",
    "2. Pull CDNs: In a Pull CDN situation, the cache is updated based on request. When the client sends a request that requires static assets to be fetched from the CDN if the CDN doesn't have it, then it will fetch the newly updated assets from the origin server and populate its cache with this new asset, and then send this new cached asset to the user. <br> Contrary to the Push CDN, this requires less maintenance because cache updates on CDN nodes are performed based on requests from the client to the origin server. Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.\n",
    "\n",
    "Disadvantages\n",
    "1. As we all know good things come with extra costs, so let's discuss some disadvantages of CDNs:\n",
    "\n",
    "2. Extra charges: It can be expensive to use a CDN, especially for high-traffic services.\n",
    "3. Restrictions: Some organizations and countries have blocked the domains or IP addresses of popular CDNs.\n",
    "4. Location: If most of our audience is located in a country where the CDN has no servers, the data on our website may have to travel further than without using any CDN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Availability\n",
    "Availability is the time a system remains operational to perform its required function in a specific period. It is a simple measure of the percentage of time that a system, service, or machine remains operational under normal conditions.\n",
    "- Replication\n",
    "- Load Balancers\n",
    "- Geo-distribution\n",
    "\n",
    "Strategies for Improving Availability\n",
    "1. Redundancy: Redundancy involves having backup components that can take over when primary components fail.\n",
    "   - Server Redundancy: Deploying multiple servers to handle requests, ensuring that if one server fails, others can continue to provide service.\n",
    "   - Database Redundancy: Creating a replica database that can take over if the primary database fails.\n",
    "   - Geographic Redundancy: Distributing resources across multiple geographic locations to mitigate the impact of regional failures.\n",
    "2. Load Balancing: Load balancing distributes incoming network traffic across multiple servers to ensure no single server becomes a bottleneck, enhancing both performance and availability.\n",
    "   - Hardware Load Balancers: Physical devices that distribute traffic based on pre-configured rules.\n",
    "   - Software Load Balancers: Software solutions that manage traffic distribution, such as HAProxy, Nginx, or cloud-based solutions like AWS Elastic Load Balancer.\n",
    "3. Data Replication: Data replication involves copying data from one location to another to ensure that data is available even if one location fails.\n",
    "   - Synchronous Replication: Data is replicated in real-time to ensure consistency across locations.\n",
    "   - Asynchronous Replication: Data is replicated with a delay, which can be more efficient but may result in slight data inconsistencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Nine's of availability\n",
    "\n",
    "Availability is often quantified by uptime (or downtime) as a percentage of time the service is available. It is generally measured in the number of 9s.\n",
    "\n",
    "$$\n",
    "\\mathcal{Availability = \\frac{Uptime}{(Uptime + Downtime)}}\n",
    "$$\n",
    "\n",
    "If availability is 99.00% available, it is said to have \"2 nines\" of availability, and if it is 99.9%, it is called \"3 nines\", and so on.\n",
    "\n",
    "| Availability (Percent)   | Downtime (Year)    | Downtime (Month)  | Downtime (Week)    |\n",
    "| ------------------------ | ------------------ | ----------------- | ------------------ |\n",
    "| 90% (one nine)           | 36.53 days         | 72 hours          | 16.8 hours         |\n",
    "| 99% (two nines)          | 3.65 days          | 7.20 hours        | 1.68 hours         |\n",
    "| 99.9% (three nines)      | 8.77 hours         | 43.8 minutes      | 10.1 minutes       |\n",
    "| 99.99% (four nines)      | 52.6 minutes       | 4.32 minutes      | 1.01 minutes       |\n",
    "| 99.999% (five nines)     | 5.25 minutes       | 25.9 seconds      | 6.05 seconds       |\n",
    "| 99.9999% (six nines)     | 31.56 seconds      | 2.59 seconds      | 604.8 milliseconds |\n",
    "| 99.99999% (seven nines)  | 3.15 seconds       | 263 milliseconds  | 60.5 milliseconds  |\n",
    "| 99.999999% (eight nines) | 315.6 milliseconds | 26.3 milliseconds | 6 milliseconds     |\n",
    "| 99.9999999% (nine nines) | 31.6 milliseconds  | 2.6 milliseconds  | 0.6 milliseconds   |\n",
    "\n",
    "### Availability in Sequence vs Parallel\n",
    "\n",
    "If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel.\n",
    "\n",
    "#### Sequence\n",
    "\n",
    "Overall availability decreases when two components are in sequence.\n",
    "\n",
    "$$\n",
    "Availability \\space (Total) = Availability \\space (Foo) * Availability \\space (Bar)\n",
    "$$\n",
    "\n",
    "For example, if both `Foo` and `Bar` each had 99.9% availability, their total availability in sequence would be 99.8%.\n",
    "\n",
    "#### Parallel\n",
    "\n",
    "Overall availability increases when two components are in parallel.\n",
    "\n",
    "$$\n",
    "Availability \\space (Total) = 1 - (1 - Availability \\space (Foo)) * (1 - Availability \\space (Bar))\n",
    "$$\n",
    "\n",
    "For example, if both `Foo` and `Bar` each had 99.9% availability, their total availability in parallel would be 99.9999%.\n",
    "\n",
    "### Availability vs Reliability\n",
    "\n",
    "If a system is reliable, it is available. However, if it is available, it is not necessarily reliable. In other words, high reliability contributes to high availability, but it is possible to achieve high availability even with an unreliable system.\n",
    "\n",
    "### High availability vs Fault Tolerance\n",
    "\n",
    "Both high availability and fault tolerance apply to methods for providing high uptime levels. However, they accomplish the objective differently.\n",
    "\n",
    "A fault-tolerant system has no service interruption but a significantly higher cost, while a highly available system has minimal service interruption. Fault-tolerance requires full hardware redundancy as if the main system fails, with no loss in uptime, another system should take over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability:\n",
    "The system should continue to work correctly (performing the correct function at the desired level of performance) even in the face of adversity (hardware or soft‐ ware faults, and even human error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can We Improve databae performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data partitioning:\n",
    "Data partitioning is a technique to break up a database into many smaller parts. It is the process of splitting up a database or a table across multiple machines to improve the manageability, performance, and availability of a database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Horizontal Partitioning (or Sharding)\n",
    "In this strategy, we split the table data horizontally based on the range of values defined by the partition key. It is also referred to as database sharding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vertical partitioning:\n",
    "In vertical partitioning, we partition the data vertically based on columns. We divide tables into relatively smaller tables with few elements, and each part is present in a separate partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replication\n",
    "Replication involves copying and maintaining data across multiple servers or nodes to improve scalability, availability, and fault tolerance.\n",
    "- Master-Master Replication\n",
    "- Master-Slave Replication\n",
    "\n",
    "`Replication Techniques`:\n",
    "1. Synchronous Replication\n",
    "2. Asynchronous Replication\n",
    "3. Streaming Replication\n",
    "4. Snapshot Replication\n",
    "5. Log-Based Replication (Log Shipping)\n",
    "6. Statement-Based Replication\n",
    "7. Row-Based Replication\n",
    "8. Logical Replication\n",
    "\n",
    "| Type                | Latency  | Consistency        | Scalability | Use Cases                                       |\n",
    "|---------------------|----------|--------------------|-------------|------------------------------------------------|\n",
    "| **Synchronous**     | High     | Strong             | Limited     | Financial systems, critical applications       |\n",
    "| **Asynchronous**    | Low      | Eventual           | High        | Social media, write-heavy systems              |\n",
    "| **Snapshot**        | High     | Weak (interval-based) | Moderate  | Reporting, data warehouses                     |\n",
    "| **Log Shipping**    | Moderate | Eventual           | Limited     | Disaster recovery, backups                     |\n",
    "| **Statement-Based** | Low      | Dependent on SQL   | Limited     | Legacy systems, simple workloads               |\n",
    "| **Row-Based**       | Low      | Strong             | Moderate    | Complex updates, transactional systems         |\n",
    "| **Logical Replication** | Moderate | Strong (selective) | High     | ETL, multi-tenant systems                      |\n",
    "| **Streaming**       | Low      | Strong             | High        | High-availability systems, read-heavy apps     |\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1#Synchronous Replication\n",
    "In synchronous replication, data is written to both the primary and replica databases simultaneously. A transaction is not considered complete until it is successfully committed on all replicas.\n",
    "\n",
    "Key Characteristics:\n",
    "Guarantees strong consistency between the primary and replicas.\n",
    "Slower write performance due to the need for all replicas to acknowledge the write.\n",
    "Advantages:\n",
    "Ensures no data loss during a failover.\n",
    "Suitable for critical applications requiring strong consistency.\n",
    "Disadvantages:\n",
    "High latency, especially in geographically distributed setups.\n",
    "Slower transaction throughput.\n",
    "Use Cases:\n",
    "Financial systems where data accuracy is critical.\n",
    "Systems that cannot tolerate even a single transaction loss.\n",
    "\n",
    "##### 2#Asynchronous Replication\n",
    "Definition:\n",
    "In asynchronous replication, data is written to the primary database, and the update is propagated to replicas later. The primary does not wait for confirmation from the replicas.\n",
    "\n",
    "Key Characteristics:\n",
    "Improves write performance since transactions complete quickly on the primary.\n",
    "Risk of data loss during failover due to replication lag.\n",
    "Advantages:\n",
    "High performance with low latency.\n",
    "Scales well for write-heavy systems.\n",
    "Disadvantages:\n",
    "Data on replicas may be slightly out of sync with the primary.\n",
    "Not suitable for applications requiring strong consistency.\n",
    "Use Cases:\n",
    "Applications prioritizing high write throughput over immediate consistency (e.g., social media, logging systems).\n",
    "\n",
    "##### 3#Snapshot Replication\n",
    "Snapshot replication creates a copy of the entire database or parts of it at regular intervals and applies it to the replicas.\n",
    "\n",
    "Key Characteristics:\n",
    "Best for scenarios where changes occur less frequently.\n",
    "Does not provide real-time synchronization.\n",
    "Advantages:\n",
    "Simple to implement.\n",
    "Suitable for data warehouses or analytical systems.\n",
    "Disadvantages:\n",
    "High latency due to periodic updates.\n",
    "Resource-intensive during snapshot generation.\n",
    "Use Cases:\n",
    "Reporting or analytics systems where real-time updates are not required.\n",
    "##### 4#Log-Based Replication (Log Shipping)\n",
    "Definition:\n",
    "In log-based replication, transaction logs from the primary database are shipped to replicas, where they are replayed to maintain consistency.\n",
    "\n",
    "Key Characteristics:\n",
    "Works at the binary log level, applying changes efficiently.\n",
    "Replicas are often read-only.\n",
    "Advantages:\n",
    "Suitable for disaster recovery.\n",
    "Provides a warm standby for failover.\n",
    "Disadvantages:\n",
    "Replication lag due to log shipping intervals.\n",
    "Complexity in managing log storage.\n",
    "Use Cases:\n",
    "Disaster recovery scenarios.\n",
    "Maintaining read-only replicas for backup or reporting.\n",
    "\n",
    "##### 5#Statement-Based Replication\n",
    "Definition:\n",
    "In statement-based replication, the primary sends the actual SQL statements executed to replicas, which then execute the same statements.\n",
    "\n",
    "Key Characteristics:\n",
    "Easy to understand and implement.\n",
    "Relies on idempotent SQL operations for consistency.\n",
    "Advantages:\n",
    "Simple and lightweight in certain scenarios.\n",
    "Disadvantages:\n",
    "Prone to inconsistencies if SQL statements produce non-deterministic results.\n",
    "Limited support for complex transactions.\n",
    "Use Cases:\n",
    "Legacy systems with simpler workloads.\n",
    "##### 6#Row-Based Replication\n",
    "Definition:\n",
    "Row-based replication sends the actual data changes (row updates) to replicas rather than SQL statements.\n",
    "\n",
    "Key Characteristics:\n",
    "Ensures consistent replication of changes.\n",
    "Avoids issues with non-deterministic SQL execution.\n",
    "Advantages:\n",
    "Reliable for complex transactions and queries.\n",
    "Consistency is easier to maintain.\n",
    "Disadvantages:\n",
    "More data is transferred, increasing network usage.\n",
    "Higher overhead compared to statement-based replication.\n",
    "Use Cases:\n",
    "Systems with complex updates or where data consistency is paramount.\n",
    "##### 7#Logical Replication\n",
    "Definition:\n",
    "Logical replication operates at a higher abstraction level, replicating changes at the logical data level (e.g., table rows or subsets of data).\n",
    "\n",
    "Key Characteristics:\n",
    "Supports partial replication (specific tables or rows).\n",
    "Allows cross-version and cross-database replication.\n",
    "Advantages:\n",
    "Fine-grained control over replicated data.\n",
    "Useful for heterogeneous systems.\n",
    "Disadvantages:\n",
    "Slower than binary or streaming replication for high-volume workloads.\n",
    "More complex to configure.\n",
    "Use Cases:\n",
    "ETL pipelines and data integration.\n",
    "Multi-tenant systems with selective data replication.\n",
    "\n",
    "##### 8#Streaming Replication\n",
    "Definition:\n",
    "Streaming replication continuously streams changes from the primary to replicas in near real-time.\n",
    "\n",
    "Key Characteristics:\n",
    "Operates at the WAL (Write-Ahead Log) level.\n",
    "Replicas stay nearly synchronized.\n",
    "Advantages:\n",
    "Low-latency updates to replicas.\n",
    "Suitable for read-heavy workloads.\n",
    "Disadvantages:\n",
    "Complexity in managing replicas.\n",
    "Requires robust networking.\n",
    "Use Cases:\n",
    "High-availability systems needing near real-time synchronization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to Right type of Replication\n",
    "1. `High Consistency and Low Latency:`\n",
    "   - Use synchronous replication or streaming replication.\n",
    "   - Ideal for critical applications like banking or stock trading.\n",
    "2. `High Scalability:`\n",
    "   - Use asynchronous replication or logical replication.\n",
    "   - Ideal for distributed systems or read-heavy applications.\n",
    "3. `Disaster Recovery`:\n",
    "   - Use log shipping or snapshot replication.\n",
    "   - Ideal for backup systems or warm standbys.\n",
    "4. `Data Integration`:\n",
    "   - Use logical replication for selective data replication.\n",
    "   - Ideal for multi-database environments or ETL pipelines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Master-slave replication:\n",
    "In master-slave replication, one node (the master) handles all write operations, while one or more replicas (slaves) receive updates from the master and are used primarily for read operations.\n",
    "\n",
    "Key Characteristics:\n",
    "Only the master can handle writes.\n",
    "Slaves are typically read-only and receive updates asynchronously or synchronously from the master.\n",
    "Ensures strong consistency when using synchronous replication but may have eventual consistency with asynchronous setups.\n",
    "Advantages:\n",
    "Simple to implement and manage.\n",
    "Improves read performance by offloading read traffic to slaves.\n",
    "Master serves as the authoritative source for writes, reducing the risk of conflicts.\n",
    "Disadvantages:\n",
    "The master is a single point of failure unless failover mechanisms are implemented.\n",
    "Write scalability is limited to the master node.\n",
    "Slaves may lag behind the master in asynchronous replication setups.\n",
    "Use Cases:\n",
    "Read-heavy applications, such as reporting systems or content delivery platforms.\n",
    "Systems requiring a primary source of truth for writes with replicas for redundancy.\n",
    "Scenarios needing minimal conflict resolution complexity.\n",
    "\n",
    "##### Pros:\n",
    "1. Backups of the entire database of relatively no impact on the master.\n",
    "2. Applications can read from the slave(s) without impacting the master.\n",
    "3. Slaves can be taken offline and synced back to the master without any downtime.\n",
    "##### Cons:\n",
    "1. Replication adds more hardware and additional complexity.\n",
    "2. Downtime and possibly loss of data when a master fails.\n",
    "3. All writes also have to be made to the master in a master-slave architecture.\n",
    "4. The more read slaves, the more we have to replicate, which will increase replication lag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Master-master replication\n",
    "Master-master replication (also called bidirectional replication) involves two or more database nodes (masters) that can both read and write. Changes made to any master are synchronized with the others.\n",
    "\n",
    "Key Characteristics:\n",
    "Both nodes serve as primaries and allow read and write operations.\n",
    "Typically uses conflict resolution mechanisms to handle concurrent updates.\n",
    "Suitable for distributed systems where multiple nodes need write access.\n",
    "Advantages:\n",
    "High availability: If one master fails, another master can take over immediately.\n",
    "Improved write performance in distributed systems.\n",
    "Supports geographically distributed applications with local write capability.\n",
    "Disadvantages:\n",
    "Risk of data conflicts if the same row is updated concurrently on different masters.\n",
    "More complex to implement and maintain.\n",
    "Increased latency in propagating changes between masters.\n",
    "Use Cases:\n",
    "Applications requiring geographically distributed writes (e.g., global e-commerce platforms).\n",
    "Systems needing high availability with multi-primary setups.\n",
    "Workloads with minimal likelihood of concurrent data modification conflicts.\n",
    "\n",
    "##### Pros:\n",
    "1. Applications can read from both masters.\n",
    "2. Distributes write load across both master nodes.\n",
    "3. Simple, automatic, and quick failover.\n",
    "##### Cons:\n",
    "1. Not as simple as master-slave to configure and deploy.\n",
    "2. Either loosely consistent or have increased write latency due to synchronization.\n",
    "3. Conflict resolution comes into play as more write nodes are added and as latency increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WAL:\n",
    "Write-Ahead Logging is a transactional logging mechanism where all changes to the database are first written to a log (WAL file) before being applied to the actual database files.\n",
    "\n",
    "Purpose:\n",
    "Durability: Ensures that committed transactions are recoverable even after a crash.\n",
    "Crash Recovery: Enables the database to restore its state to the point of failure by replaying the WAL.\n",
    "How It Works:\n",
    "Changes from a transaction are written to the WAL (log file) in sequential order.\n",
    "Once the log is written to disk, the transaction is marked as committed.\n",
    "Periodically, the WAL content is flushed to the main database files through a checkpointing process.\n",
    "During recovery, the WAL is replayed to reapply committed changes or roll back incomplete transactions.\n",
    "Advantages:\n",
    "Provides atomicity and durability (ACID compliance).\n",
    "Fast sequential writes to WAL improve performance.\n",
    "Simplifies crash recovery by replaying the WAL.\n",
    "Limitations:\n",
    "Only handles durability and crash recovery within the same database instance.\n",
    "Does not inherently provide high availability or redundancy.\n",
    "Use Cases:\n",
    "Local durability and crash recovery in transactional databases (e.g., PostgreSQL, MySQL-InnoDB, SQLite).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Shipping\n",
    "Log Shipping\n",
    "Definition:\n",
    "Log Shipping involves copying and applying transaction logs (WAL files or similar) from a primary database to one or more secondary databases to maintain redundancy or create read-only replicas.\n",
    "\n",
    "Purpose:\n",
    "High Availability: Provides a backup database that can be used in case of primary database failure.\n",
    "Disaster Recovery: Ensures data consistency across geographically distributed replicas.\n",
    "Read Scalability: Secondary databases can be used for read queries, offloading the primary.\n",
    "How It Works:\n",
    "The primary database periodically writes its transaction logs (e.g., WAL files) to disk.\n",
    "These logs are shipped (copied) to secondary databases over the network.\n",
    "Secondary databases apply the logs to replicate the state of the primary database.\n",
    "Advantages:\n",
    "Provides redundancy and high availability.\n",
    "Enables geographical distribution for disaster recovery.\n",
    "Can offload read traffic to secondary replicas (if supported by the setup).\n",
    "Limitations:\n",
    "Replication Lag: Secondary databases may not be up-to-date due to the periodic nature of log shipping.\n",
    "Read-Only Secondary: Secondary databases are typically read-only and cannot process write operations.\n",
    "Manual Failover: Requires intervention to promote a secondary database to primary in case of failure.\n",
    "Use Cases:\n",
    "Disaster recovery setups with offsite replicas.\n",
    "Creating read-only replicas for reporting and analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write -Ahead Log vs Log Shipping\n",
    "\n",
    "| Feature              | Write-Ahead Logging (WAL)                     | Log Shipping                                    |\n",
    "|----------------------|-----------------------------------------------|------------------------------------------------|\n",
    "| **Purpose**          | Durability and crash recovery                | High availability and redundancy               |\n",
    "| **Scope**            | Local to a single database instance          | Across primary and secondary nodes             |\n",
    "| **Mechanism**        | Logs are written before changes are applied  | Logs are shipped and replayed on replicas      |\n",
    "| **Redundancy**       | No                                            | Yes                                            |\n",
    "| **Recovery**         | Replays WAL on crash within the same instance | Secondary replicas provide backup              |\n",
    "| **Replication Lag**  | None                                          | Possible lag (periodic log shipping)           |\n",
    "| **Write Scalability**| Does not improve write scalability           | Does not improve write scalability             |\n",
    "| **Read Scalability** | Not applicable                               | Read-only secondary replicas can scale reads   |\n",
    "| **Failure Handling** | Ensures local durability                     | Requires manual or automated failover          |\n",
    "| **Examples**         | PostgreSQL, MySQL-InnoDB, SQLite             | PostgreSQL, SQL Server, Oracle                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronous replication\n",
    "In synchronous replication, data is written to primary storage and the replica simultaneously. As such, the primary copy and the replica should always remain synchronized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asynchronous replication\n",
    "asynchronous replication copies the data to the replica after the data is already written to the primary storage. Although the replication process may occur in near-real-time, it is more common for replication to occur on a scheduled basis and it is more cost-effective. It will violates the `Consistcy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Sharding\n",
    "Database sharding is a `horizontal scaling` technique used to split a large database into smaller, independent pieces called shards.\n",
    "\n",
    "Partitioning criteria:\n",
    "1. Hash-Based\n",
    "2. List-Based\n",
    "3. Range Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pros:\n",
    "1. Availability: Provides logical independence to the partitioned database, ensuring the high availability of our application. Here individual partitions can be managed independently.\n",
    "2. Scalability: Proves to increase scalability by distributing the data across multiple partitions.\n",
    "3. Security: Helps improve the system's security by storing sensitive and non-sensitive data in different partitions. This could provide better manageability and security to sensitive data.\n",
    "4. Query Performance: Improves the performance of the system. Instead of querying the whole database, now the system has to query only a smaller partition.\n",
    "5. Data Manageability: Divides tables and indexes into smaller and more manageable units.\n",
    "6. Geographical Distribution: Sharding allows you to strategically place shards closer to your users, reducing latency and improving the user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cons:\n",
    "1. Complexity: Sharding introduces additional complexity, requiring careful planning and management.\n",
    "\n",
    "2. Data Consistency: Maintaining data consistency across shards can be challenging, especially when data needs to be joined or aggregated from multiple shards.\n",
    "\n",
    "3. Cross-shard Joins: Performing joins across multiple shards can be complex and computationally expensive.\n",
    "\n",
    "4. Data Rebalancing: As data volumes grow, shards may become unevenly distributed, requiring rebalancing to maintain optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalization:\n",
    "Denormalization attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins. Some RDBMS such as PostgreSQL and Oracle support materialized views which handle the work of storing redundant information and keeping redundant copies consistent.\n",
    "\n",
    "Pros:\n",
    "1. Retrieving data is faster.\n",
    "2. Writing queries is easier.\n",
    "3. Reduction in number of tables.\n",
    "4. Convenient to manage.\n",
    "\n",
    "Disadvantages\n",
    "1. Expensive inserts and updates.\n",
    "2. Increases complexity of database design.\n",
    "3. Increases data redundancy.\n",
    "4. More chances of data inconsistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACID and BASE consitency Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACID\n",
    "1. **Atomicity**: Atomicity ensures that a transaction is treated as an indivisible unit of work. It means that either all the operations within a transaction are successfully completed, or none of them are applied to the database.\n",
    "2. **Consistency**: Consistency ensures that a transaction brings the database from `one valid state` to `another valid state`, maintaining all data integratity constraints, as `unique constraints, foreign key constraints, and check constraints`, all of which are satisfied `before and after the transaction`.\n",
    "3. **Isolation**: Isolation ensures that transactions are executed in a way that they do not interfere with each other. It means that the `intermediate state of a transaction` is not visible to `other transactions` until it is `committed`.\n",
    "4. **Durability**: Once the transaction has been completed and the writes and updates have been written to the disk, it will remain in the system even if a system failure occurs.\n",
    "\n",
    "While ACID properties are foundational to RDBMS, NoSQL databases like MongoDB often sacrifice some ACID properties for `performance and scalability`.\n",
    "\n",
    "#### How does it work internally?\n",
    "1. Log-Based Mechanism: Most databases use a Write-Ahead Logging (WAL) mechanism to ensure durability. Changes are first written to a transaction log before being applied to the database.\n",
    "2. Locks: Locks are used to ensure isolation.\n",
    "   - Shared Lock: Prevents data from being modified but allows reads.\n",
    "   - Exclusive Lock: Prevents other transactions from `reading or modifying` the data.\n",
    "3. Temporary State: Changes are stored in a temporary area until the transaction is committed.\n",
    "4. Commit Process: The database ensures all changes are written to the disk and the log is updated to mark the transaction as complete.\n",
    "5. Rollback Process: If a rollback is triggered, the database uses the transaction log to reverse all changes made during the transaction.\n",
    "\n",
    "\n",
    "### BASE\n",
    "BASE stands for `basically available`, `soft state`, and `eventually consistent`. The acronym highlights that BASE is opposite of ACID, like their chemical equivalents.\n",
    "1. `Basically available:` Basically available is the database’s concurrent accessibility by users at all times. For example, during a sudden surge in traffic on an ecommerce platform, the system may prioritize serving product listings and accepting orders. Even if there is a slight delay in updating inventory quantities, users continue to check out items.\n",
    "2. `Soft Sate:` Indicates that the state of the system may change over time, the system may not be in a consistent state at all times.\n",
    "3. `Eventually consistent:` Eventually consistent means the record will achieve consistency when all the concurrent updates have been completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAP theorem:\n",
    "CAP theorem states that a distributed system can deliver only two of the three desired characteristics Consistency, Availability, and Partition tolerance (CAP).\n",
    "\n",
    "1. ***Consistency***: Consistency means that all clients read `the same data or error` at the same time, no matter which node they connect to. \n",
    "   - For this to happen, whenever data is written to one node, it must be instantly `forwarded or replicated` across all the `nodes` in the system before the write is deemed \"successful\".\n",
    "\n",
    "2. **Availability**: Availability means that any client making a request for data gets a response, even if one or more nodes are down.\n",
    "3. **Partition tolerance**: The system continues to operate despite the communication between nodes being unreliable or lost.\n",
    "\n",
    "### The CAP Trade-Off: Choosing 2 out of 3:\n",
    "1. ***CP (Consistency and Partition Tolerance):*** Strong consistency but secrifice availability during partition.\n",
    "   - If a partition occurs the system halts to ensure data consistency. \n",
    "   - RDBMS: `MySQL and PostgreSQL` when configured with `synchronized replication`, Distributed transaction`(2-PC or 3-PC)`. \n",
    "   - Examples: `Banking systems`, `booking System`, `Inventory System`\n",
    "2. AP (Availability and Partition Tolerance): High availability but temporarily secrifice consistency.\n",
    "   - `User Experience:` Applications where user experience is critical and users expect the system to be `responsive` at all times, even if some data is slightly out of date.\n",
    "   - `Scalability:` Systems that need to scale `horizontally` and handle `large volumes of traffic`, such as large-scale web applications.\n",
    "   - `Fault Tolerance:` Environments where network partitions are common, and the system must continue to operate despite node failures or network issues.\n",
    "   - A shopping cart system is designed to always accept items, prioritizing availability.\n",
    "   - NoSQL databases`(Cassandra, DynamoDB)`\n",
    "3. CA (Consistency and Availability): In the absence of partitions, a system can be both consistent and available. However, network partitions are inevitable in distributed systems, making this combination impractical. `Single-node databases`\n",
    "   - Systems that operate within a single node or do not encounter partitions can achieve both consistency and availability.\n",
    "   - `RDMS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Transactions\n",
    "A `transaction` is a sequence of database operations that are executed as a single unit of work. A distributed transaction is a set of operations on data that is performed across two or more databases. It is typically coordinated across separate nodes connected by a network, but may also span multiple databases on a single server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-Phase commit\n",
    "The two-phase commit (2PC) protocol is a distributed algorithm that coordinates all the processes that participate in a distributed transaction on whether to commit or abort (roll back) the transaction.\n",
    "\n",
    "This protocol achieves its goal even in many cases of temporary system failure and is thus widely used. However, it is not resilient to all possible failure configurations, and in rare cases, manual intervention is needed to remedy an outcome.\n",
    "\n",
    "This protocol requires a coordinator node, which basically coordinates and oversees the transaction across different nodes. The coordinator tries to establish the consensus among a set of processes in two phases, hence the name.\n",
    "\n",
    "***Prepare phase:***\n",
    "The prepare phase involves the coordinator node collecting consensus from each of the participant nodes. The transaction will be aborted unless each of the nodes responds that they're prepared.\n",
    "\n",
    "***Commit phase:***\n",
    "If all participants respond to the coordinator that they are prepared, then the coordinator asks all the nodes to commit the transaction. If a failure occurs, the transaction will be rolled back.\n",
    "\n",
    "#### Cons:\n",
    "- What if one of the nodes crashes?\n",
    "- What if the coordinator itself crashes?\n",
    "- It is a blocking protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three-phase commit:\n",
    "Three-phase commit (3PC) is an extension of the two-phase commit where the commit phase is split into two phases. This helps with the blocking problem that occurs in the two-phase commit protocol.\n",
    "\n",
    "1. Prepare phase: This phase is the same as the two-phase commit.\n",
    "\n",
    "2. Pre-commit phase: Coordinator issues the pre-commit message and all the participating nodes must acknowledge it. If a participant fails to receive this message in time, then the transaction is aborted.\n",
    "\n",
    "3. Commit phase: This step is also similar to the two-phase commit protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does Pre-commit phase helpful?\n",
    "1. If the participant nodes are found in this phase, that means that every participant has completed the first phase. The completion of prepare phase is guaranteed.\n",
    "2. Every phase can now time out and avoid indefinite waits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saga\n",
    "A saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choreography: Each local transaction publishes domain events that trigger local transactions in other services.\n",
    "2. Orchestration: An orchestrator tells the participants what local transactions to execute.\n",
    "\n",
    "Problems:\n",
    "1. The Saga pattern is particularly hard to debug.\n",
    "2. There's a risk of cyclic dependency between saga participants.\n",
    "3. Lack of participant data isolation imposes durability challenges.\n",
    "4. Testing is difficult because all services must be running to simulate a transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SaaS and PaaS and IaaS\n",
    "1. **SaaS**: SaaS delivers fully functional software applications over the internet.\n",
    "   - End-to-end software solutions for users.\n",
    "   - Accessible through browsers or thin clients (e.g., mobile apps).\n",
    "   - Managed entirely by the service provider (infrastructure, platform, and software)\n",
    "   - `Example:` Google Drive, Salesforce\n",
    "2. **PaaS**: PaaS provides a platform or environment for developers to build, deploy, and manage applications without managing the underlying infrastructure (servers, storage, networking). It lies between IaaS (Infrastructure as a Service) and SaaS.\n",
    "   - Advantages:\n",
    "     - Built-in Features: Offers services like databases, middleware, and caching out of the box.\n",
    "     - Faster Development: Pre-configured development tools and frameworks accelerate application development.\n",
    "     - Example: Heroku, AWS Elastic Beanstalk, Microsoft Azure App Service\n",
    "3. **IaaS**: IaaS provides virtualized computing resources over the internet, including servers, storage, and networking. Users have more control over the infrastructure, allowing them to install and manage their operating systems, applications, and configurations.\n",
    "   - Provides virtual machines, storage, and networking resources.\n",
    "   - Users have control over the operating system and applications.\n",
    "   - Pay-as-you-go pricing model.\n",
    "   - Example: Amazon Web Services (AWS) EC2, Microsoft Azure Virtual Machines.\n",
    "\n",
    "| **Aspect**      | **SaaS**                              | **PaaS**                              | **IaaS**                              |\n",
    "|-----------------|---------------------------------------|---------------------------------------|---------------------------------------|\n",
    "| **Control**     | Least (managed by provider)           | Moderate (development and deployment) | Most (full control over infrastructure) |\n",
    "| **Maintenance** | Provider                              | Provider                              | User                                  |\n",
    "| **Flexibility** | Limited customization                 | Moderate customization                | High customization                    |\n",
    "| **Use Case**    | End-user applications                 | Application development               | Infrastructure management             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Tenant?\n",
    "A tenant in software architecture refers to a group of users who share access to a common instance of a software application but have their data logically or physically isolated from other groups. The concept of a tenant is central to multi-tenancy in cloud computing and SaaS (Software as a Service) applications.\n",
    "1. **Single-Tenant**\n",
    "2. **Multi-Tenant**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Tenant\n",
    "In a single-tenant architecture, each customer (tenant) has a dedicated instance of the application, including its database and resources. No sharing occurs between tenants.\n",
    "- Separate infrastructure and databases for each tenant.\n",
    "- Customization can be tailored to the specific tenant’s needs.\n",
    "- Data is isolated and secured for each tenant.\n",
    "- `Ex`: A private banking application where each bank gets its own isolated instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Tenant\n",
    "In a multi-tenant architecture, multiple customers (tenants) share the same application instance, database, and resources. However, data is logically isolated to ensure privacy.\n",
    "- Shared infrastructure, application instance, and database among tenants.\n",
    "- Logical data isolation using mechanisms like tenant IDs.\n",
    "- Centralized maintenance and updates.\n",
    "- `Ex`: Google Workspace: Multiple organizations use shared infrastructure while data is isolated.\n",
    "\n",
    "### Summary\n",
    "| **Aspect**       | **Single-Tenant**                    | **Multi-Tenant**                      |\n",
    "|------------------|--------------------------------------|---------------------------------------|\n",
    "| **Infrastructure** | Dedicated instance per tenant.       | Shared instance among tenants.         |\n",
    "| **Data Isolation** | Complete physical isolation.         | Logical isolation within the same database. |\n",
    "| **Customization** | High; tailored per tenant.           | Limited; same application for all tenants. |\n",
    "| **Cost**          | Higher due to non-shared resources.   | Lower due to shared resources.         |\n",
    "| **Maintenance**   | Separate updates and backups.        | Centralized updates and backups.       |\n",
    "| **Performance**   | Not affected by other tenants.        | One tenant can potentially affect others. |\n",
    "| **Scalability**   | Harder to scale for many tenants.     | Easier to scale due to shared resources. |\n",
    "| **Security**      | Stronger physical data isolation.     | Requires robust logical isolation.      |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
