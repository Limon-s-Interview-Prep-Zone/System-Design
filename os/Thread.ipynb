{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process:\n",
    "A process is an independent and isolated execution unit with its own memory space, resources and system state.\n",
    "- A web browser\n",
    "- A word processor\n",
    "\n",
    "### Thread:\n",
    "A thread is a smaller unit wihin a process, which contains multiple threads, all sharing same memory space but performing different task simultaneously.\n",
    "- thread-1: rendering web page\n",
    "- thread-2: receving data from internet\n",
    "\n",
    "### Multi-threading:\n",
    "Muliti-threading means when multiple threads are executing within the same **`process`**.\n",
    "- thread-1: rendering web page\n",
    "- thread-2: receving data from internet\n",
    "\n",
    "### Multitasking:\n",
    "Multitasking refers to a system running multiple `processes` or `programs` at the same time.\n",
    "- process-1: writing a document\n",
    "- process-2: running a video player\n",
    "- process-3: browsing social media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread\n",
    "1. Thread life cycle\n",
    "2. Single thread vs multi-thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread life cycle:\n",
    "1. Creation: The thread is created but not yet started. `thread()`\n",
    "2. Runable: The thread is in the Runnable state once the `start()` method is called and is waiting for CPU time.\n",
    "3. Running: The machine is now performing its assigned task.\n",
    "   1. `sleep()`\n",
    "   2. `wait()`\n",
    "   3. `join()`: wait untill all threads has been completed.\n",
    "4. Blocking/waiting: The thread is temporarily inactive because it is waiting for some condition to be met (such as waiting for input, waiting for a lock, or waiting for a response from another system). During this time, the thread is not consuming CPU resources.\n",
    "5. Timed Waiting: The machine is paused for a specific time.\n",
    "6. Termination: The machine has finished its job and is turned off permanently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single thread vs Multithread?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threading Trade-off:\n",
    "#### Advantages:\n",
    "1. **Concurrency**: Multithreading allows multiple tasks (or threads) to run concurrently within a `single process`.\n",
    "2. **Parallelism**: On multicore systems, multithreading enables parallel execution, where multiple threads run simultaneously on **different CPU cores**.\n",
    "3. Responsiveness and Low Latency: Multithreading improves application responsiveness by allowing time-consuming tasks to run in the background, without freezing the user interface (UI). This reduces latency, as threads can process user inputs or system events immediately.\n",
    "4. Efficient Resource Utilization: Multithreading optimizes the use of system resources, especially when a task involves waiting for external input/output (I/O) operations like file reading or network access.\n",
    "5.  Asynchronous Processing: Multithreading enables asynchronous task execution, where certain tasks can run in the background without blocking the main process.\n",
    "6.  Thread Pool: Thread pooling is an important feature of multithreading that allows efficient reuse of threads. Instead of creating and destroying threads repeatedly (which is costly in terms of performance), a pool of pre-created threads is maintained, and tasks are assigned to them as needed.\n",
    "7.  Synchronization: Multithreading provides mechanisms to control access to shared resources through synchronization. This prevents race conditions, where multiple threads try to modify the same data simultaneously, ensuring consistency and correctness in the program.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disadvantages:\n",
    "##### Race condition:\n",
    "When multiple threads try to access and modify shared data simultaneously, leading to inconsistent results.\n",
    "* Thread A: Reads the account balance (let’s say $100) and plans to add $50.\n",
    "* Thread B: Simultaneously reads the balance (still $100) and plans to subtract $30.\n",
    "\n",
    "If both threads read the balance before either one writes back the updated amount, both think the account has $100. So:\n",
    "\n",
    "* Thread A adds $50 and writes $150.\n",
    "* Thread B subtracts $30 and writes $70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deadlock:\n",
    "A situation where two or more threads wait for each other to release resources, causing an infinite block.\n",
    "\n",
    "Imagine two threads, Thread A and Thread B, need two resources, Resource 1 and Resource 2, to complete their tasks.\n",
    "\n",
    "- Thread A locks Resource 1 and waits for Resource 2 to become available.\n",
    "- Thread B locks Resource 2 and waits for Resource 1 to become available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Livelock:\n",
    "A livelock occurs when threads remain active, but they can’t make progress because they continuously respond to each other. Unlike a deadlock, where threads are stuck waiting, in a livelock, the threads are still running, but they are too busy adjusting their actions to a constantly changing state.\n",
    "\n",
    "Two threads are attempting to avoid a deadlock by releasing locks when they detect that another thread holds the needed resource.\n",
    "\n",
    "- Thread A holds Lock 1 and tries to acquire Lock 2, but notices that Thread B is holding it, so Thread A releases Lock 1 and waits.\n",
    "- Thread B holds Lock 2 and tries to acquire Lock 1, but sees that Thread A is holding it, so Thread B releases Lock 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Starvation:\n",
    "Starvation occurs when a thread is perpetually denied access to resources because other threads are constantly prioritized over it.\n",
    "\n",
    "- High-Priority Thread: Continuously gets CPU time for execution.\n",
    "- Low-Priority Thread: Keeps waiting indefinitely because the high-priority thread is constantly running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Priority Inversion:\n",
    "Priority inversion occurs when a low-priority thread holds a resource that a higher-priority thread needs. While the higher-priority thread waits for the resource, medium-priority threads may continue to run, preventing the low-priority thread from completing its task and releasing the resource.\n",
    "\n",
    "- Low-Priority Thread locks a resource (e.g., a mutex).\n",
    "- High-Priority Thread needs the same resource and is blocked, waiting for the low-priority thread to release it.\n",
    "- Medium-Priority Thread doesn't need the resource but keeps getting CPU time, preventing the low-priority thread from finishing and releasing the resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Context Switching Overhead:\n",
    "Each time the operating system switches between threads, it incurs context switching overhead. This involves saving the current thread’s state (registers, program counter, etc.) and loading the next thread’s state. While necessary, frequent context switching can reduce performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Thread Pool Exhaustion\n",
    "In systems that use a thread pool, if all threads in the pool are busy, new tasks may have to wait indefinitely, leading to thread pool exhaustion. This can cause the system to become unresponsive or degrade performance if the pool size is not properly managed.\n",
    "- New requests are queued, and users experience delays or timeouts.\n",
    "- If tasks are slow to complete, it can lead to thread pool exhaustion, where no threads are available to handle new tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need Synchronization?\n",
    "In multi-threated programming, multiple threads often share shared resources such as `variable, objects and collections`. If two threads try to `read/write` the same resouces simultaneously, it leads to `race condition`, resulting in `Data coruption`.\n",
    "\n",
    "Consider two threads `Thread1` and `Thread2`, both try to increment a shared counter without synchronization with initial value of `counter=5`.\n",
    "```bash\n",
    "counter++\n",
    "```\n",
    "1. `Thread1` reads the value `counter=5`\n",
    "2. `Thread2` also reads the value `counter=5`\n",
    "3. `Thread1` increments the value `counter=6`\n",
    "4. `Thread2` also increments the value `counter=6`\n",
    "\n",
    "With synchonization:\n",
    "1. `Thread1` reads the value `counter=5` and `lock` this.\n",
    "2. `Thread2` tries to read the value but has to wait.\n",
    "3. `Thread1` increments the value `counter=6`\n",
    "4. `Thread2` get the current value of `counter=6` then increments to `7`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronization Technique for c#\n",
    "1. `lock:` Lock a section of code, which ensures that only one thread can enter the critical section at a time.\n",
    "\n",
    "2. `Monitor:` Provides fine-grained control for lacking, with explicit lock management using `Monitor.Enter` and `Monitor.Exit`\n",
    "\n",
    "3. `Mutex:` A system-wide synchronization technique or A Mutex is a synchronization primitive that can be used to manage access to a resource `across multiple processes`, not just multiple threads. `mutex.WaitOne()` and ` mutex.ReleaseMutex()`.\n",
    "    ```bash\n",
    "        private static readonly object _monitorLock = new object();\n",
    "\n",
    "        public void ExampleMethod()\n",
    "        {\n",
    "            Monitor.Enter(_monitorLock);\n",
    "            try\n",
    "            {\n",
    "                // Critical section of code\n",
    "            }\n",
    "            finally\n",
    "            {\n",
    "                Monitor.Exit(_monitorLock);\n",
    "            }\n",
    "        }\n",
    "\n",
    "    ```\n",
    "\n",
    "4. `Semaphore and SemaphoreSlim:` A Semaphore `restricts the number of threads` that can access a particular resource or code block at the same time. `SemaphoreSlim` is a lightweight version of Semaphore used for synchronization within the same process.\n",
    "   ```bash\n",
    "   SemaphoreSlim semaphoreSlim = new SemaphoreSlim(3);\n",
    "   await semaphoreSlim.WaitAsync();\n",
    "    try\n",
    "    {\n",
    "        // Critical section of code\n",
    "    }\n",
    "    finally\n",
    "    {\n",
    "        semaphoreSlim.Release();\n",
    "    }\n",
    "   ```\n",
    "\n",
    "5. `AutoResetEvent and ManualResetEvent:` AutoResetEvent used for signaling beteen threads. Blocks a thread untill the `Set` method is called from another thread. After a single thread is released, it automatically resets to the non=signal state.\n",
    "\n",
    "6. *`Thread Safe Collections:`* This collections are designed for multi-thread scenarios and eliminate the need for manual synchronization.\n",
    "   1. *`ConcurrentDictionary<TKey, TValue>`*: A thread-safe version of `Dictionary<TKey, TValue>`.\n",
    "   2. *`ConcurrentQueue<T>`*: A thread-safe queue that allows multiple threads to `enqueue` and `dequeue` items.\n",
    "   3. *`ConcurrentStack<T>`*: A thread-safe version of `Stack<T>`.\n",
    "   4. *`ConcurrentBag<T>`*: A thread-safe, unordered collection for fast insertations and removals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
